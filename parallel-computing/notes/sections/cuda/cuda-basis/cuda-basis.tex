\subsection{CUDA Basics}

CUDA, developed by NVIDIA, is a parallel computing platform and programming model that enables developers to harness the immense computational power of NVIDIA GPUs (Graphics Processing Units).

\highspace
CUDA allows programmers to write code for GPUs using familiar programming languages like C, C++, and Fortran. This accessibility lowers the learning curve, enabling more developers to take advantage of GPU acceleration without requiring extensive knowledge of graphics programming.

\highspace
The CUDA programming model evolves with the underlying hardware architecture, ensuring that developers can maximize performance gains from the latest GPU advancements. By writing a program for a single thread and instantiating it across many parallel threads, developers can achieve significant speedups for data-parallel tasks.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{tools} \textbf{The most important function: the kernel}}
\end{flushleft}
A \textbf{kernel} is a function that runs on the GPU. When a kernel is launched, \textbf{thousands of threads execute its code simultaneously}. The programmer specifies the number of threads, each acting independently on different data elements. This approach leverages Single Instruction, Multiple Data (SIMD) and Single Program, Multiple Data (SPMD) parallelism.

\begin{examplebox}[: comparison between C and CUDA C program]
    \begin{lstlisting}[language=C]
void vsum(int* a, int* b, int* c) {
    int i;
    for (i=0; i<N; i++) {
        c[i] = a[i] + b[i];
    }
}

void main() {
    int va[N], vb[N], vc[N];
    ...
    vsum(va, vb, vc);
    ...
}
    \end{lstlisting}
    \begin{lstlisting}[language=C]
__global__ void vsum(int* a, int* b, int* c) {
    int i = ... // get unique thread ID
    c[i] = a[i] + b[i];
}

void main() {
    int va[N], vb[N], vc[N];
    ...
    vsum<<<N, 1>>>(va, vb, vc);
    ...
}
    \end{lstlisting}
    In the CUDA version, the \texttt{vsum} function is defined as a kernel using the \texttt{\_\_global\_\_} keyword, and it is launched on the GPU with a specified number of threads. Each thread processes a different element of the input arrays independently, showcasing CUDA's ability to handle parallel tasks efficiently.
\end{examplebox}