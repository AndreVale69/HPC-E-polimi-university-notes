\subsection{Technologies}

Some famous architecture to work with parallel programming:
\begin{itemize}
    \item \textbf{\underline{Verilog/VHDL}} are \emph{hardware description languages}. The target architectures are \emph{ASIC and FPGA}. The \textbf{parallelism} and the \textbf{communication} are \textbf{explicit}.
    \begin{flushleft}
        \textcolor{Green3}{\faIcon{check} \textbf{Pros}}
    \end{flushleft}
    \begin{itemize}
        \item Complete control on computation and memory
        \item No overhead introduced in the computation
        \item Provides access to potentially large computational power
    \end{itemize}
    \begin{flushleft}
        \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Cons}}
    \end{flushleft}
    \begin{itemize}
        \item Requires specific hardware (e.g., ASIC or FPGA) to implement functionality
        \item Difficult to learn: completely different programming language and programming paradigm
        \item Depends on the chosen target architecture
    \end{itemize}

    \item \textbf{\underline{MPI}} is a \emph{library}. The target architectures are \emph{Multi CPUs}. The \textbf{parallelism} is \textbf{implicit} and the \textbf{communication} is \textbf{explicit}.
    \begin{flushleft}
        \textcolor{Green3}{\faIcon{check} \textbf{Pros}}
    \end{flushleft}
    \begin{itemize}
        \item Can be adopted on different types of architecture
        \item Scalable solutions
        \item Synchronization and data communication are explicitly managed
    \end{itemize}
    \begin{flushleft}
        \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Cons}}
    \end{flushleft}
    \begin{itemize}
        \item Communication can introduce significant overhead
        \item Programming paradigm more difficult than shared memory-based ones
        \item Standard does not reflect immediately advances in architecture characteristics
    \end{itemize}

    \item \textbf{\underline{PThread}} is a \emph{library}. The target architectures are \emph{Multi-core CPUs}. The \textbf{parallelism} is \textbf{explicit} and the \textbf{communication} is \textbf{implicit}.
    \begin{flushleft}
        \textcolor{Green3}{\faIcon{check} \textbf{Pros}}
    \end{flushleft}
    \begin{itemize}
        \item Can be adopted on different types of architecture
        \item Explicit parallelism and full control over application
    \end{itemize}
    \begin{flushleft}
        \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Cons}}
    \end{flushleft}
    \begin{itemize}
        \item Task management overhead can be significant
        \item Not easily scalable solutions
        \item Low level API
    \end{itemize}

    \item \textbf{\underline{OpenMP}} is a \emph{C/Fortran extensions}. The target architectures are \emph{Multi-core CPUs}. The \textbf{parallelism} is \textbf{explicit} and the \textbf{communication} is \textbf{implicit}.
    \begin{flushleft}
        \textcolor{Green3}{\faIcon{check} \textbf{Pros}}
    \end{flushleft}
    \begin{itemize}
        \item Easy to learn
        \item Scalable solution
        \item Parallel applications can also be executed sequentially
    \end{itemize}
    \begin{flushleft}
        \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Cons}}
    \end{flushleft}
    \begin{itemize}
        \item Mainly focused on shared memory homogeneous systems
        \item Requires small interaction between tasks
    \end{itemize}

    \item \textbf{\underline{CUDA}} is a \emph{C extensions}. The target architectures are \emph{CPU plus GPU(s)}. The \textbf{parallelism} is \textbf{implicit/explicit} and the \textbf{communication} is \textbf{implicit/explicit}.
    \begin{flushleft}
        \textcolor{Green3}{\faIcon{check} \textbf{Pros}}
    \end{flushleft}
    \begin{itemize}
        \item Provides access to the computational power of GPUs
        \item Writing a CUDA kernel is quite easy
        \item Already optimized libraries
    \end{itemize}
    \begin{flushleft}
        \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Cons}}
    \end{flushleft}
    \begin{itemize}
        \item Targets only NVIDIA GPUs
        \item Difficult to extract massive parallelism from application
        \item Difficult to optimize CUDA kernel
    \end{itemize}

    \item \textbf{\underline{OpenCL}} is a \emph{C/C++ extensions and API}. The target architectures are \emph{heterogeneous architecture}. The \textbf{parallelism} is \textbf{implicit/explicit} and the \textbf{communication} is \textbf{implicit/explicit}.
    \begin{flushleft}
        \textcolor{Green3}{\faIcon{check} \textbf{Pros}}
    \end{flushleft}
    \begin{itemize}
        \item Target-independent standard
        \item Hides architecture details
        \item Same programming infrastructure for every heterogeneous architecture: CPU + GPU (and FPGA)
    \end{itemize}
    \begin{flushleft}
        \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Cons}}
    \end{flushleft}
    \begin{itemize}
        \item Difficult programming paradigm for its heterogeneity
        \item Hiding of architecture details makes difficult to obtain best performances
        \item Gradually abandoned
    \end{itemize}

    \item \textbf{\underline{Apache Spark}} is an \emph{API}. The target architectures are \emph{multi CPUs}. The \textbf{parallelism} is \textbf{implicit} and the \textbf{communication} is \textbf{implicit}.
    \begin{flushleft}
        \textcolor{Green3}{\faIcon{check} \textbf{Pros}}
    \end{flushleft}
    \begin{itemize}
        \item API for different languages
        \item Explicit parallelization and communication are not required
        \item Preinstalled on cloud provide VMs
    \end{itemize}
    \begin{flushleft}
        \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Cons}}
    \end{flushleft}
    \begin{itemize}
        \item Suitable only for big data applications
        \item Does not (yet) fully support GPUs
    \end{itemize}
\end{itemize}
Regardless of these technologies, it is quite common to mix some of them:
\begin{itemize}
    \item \textbf{OpenMP + CUDA}: allows to exploit multi-core CPU and GPU. CUDA is used to parallelize GPU code and OpenMP is used to parallelize CPU code.
    
    \item \textbf{MPI + OpenMP}: the most common scenario are:
    \begin{enumerate}
        \item MPI used to express coarser parallelism (multi CPU) and OpenMP used to express finer parallelism (multi core).
        \item MPI used to implement communication and OpenMP used to parallelize computation.
    \end{enumerate}

    \item \textbf{OpenCL + Verilog or VHDL}: in principle, hardware kernels (implemented for example on FPGA) can be used as accelerators; OpenMP used to describe parallelism among different processing elements; Verilog/VHDL used to describe hardware kernel. An example of target: Intel Xeon Scalable.
\end{itemize}