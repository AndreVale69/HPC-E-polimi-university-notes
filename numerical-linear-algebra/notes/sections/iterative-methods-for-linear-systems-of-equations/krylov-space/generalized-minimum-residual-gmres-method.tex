\subsubsection{Generalized Minimum Residual (GMRES) method}

The \definition{Generalized Minimum Residual (GMRES) method} is an iterative technique used to \textbf{solve non-symmetric linear systems} of the form $A\mathbf{x} = \mathbf{b}$. It is particularly \textbf{effective} for systems where $A$ is \textbf{non-symmetric} or even \textbf{non-square}.

\highspace
This method is a projection method. It approximates the solution by the vector in a Krylov subspace with minimal residual. It uses the Arnoldi process to generate an orthonormal basis for the Krylov subspace. This process involves a modified Gram-Schmidt orthogonalization to ensure the basis vectors are orthogonal. The main idea is that approximates the exact solution of $A\mathbf{x} = \mathbf{b}$ by the vector:
\begin{equation}
    \mathbf{x}^{\left(k\right)} \in \mathbf{x}^{\left(0\right)} + \mathcal{K}_{k}\left(A, \mathbf{r}^{\left(0\right)}\right)
\end{equation}
That minimizes the Euclidean norm of the residual $\mathbf{r}^{\left(k\right)}$.

\begin{flushleft}
    \textcolor{Green3}{\faIcon{tools} \textbf{GMRES Algorithm}}
\end{flushleft}
\begin{enumerate}
    \item \textbf{Initialization}. Choose an initial guess $\mathbf{x}^{\left(0\right)}$ and the initial residual $\mathbf{r}^{\left(0\right)} = \mathbf{b} - A\mathbf{x}^{\left(0\right)}$.

    \item \textbf{Initialize orthonormal vector}. Set $\mathbf{q}_{1} = \dfrac{\mathbf{r}^{\left(0\right)}}{{\left|\left|\mathbf{r}^{\left(0\right)}\right|\right|}_{2}}$.

    \item \textbf{Iteration}. Continue to iterate until the stopping criteria is met:
    \begin{enumerate}
        \item Compute the orthonormal $k$ vector $\mathbf{q}_{k}$ with a suitable method.
        \item Form $\mathbf{Q}_{k}$ as the $n \times k$ matrix formed by $\mathbf{q}_{1}, \mathbf{q}_{2}, \dots, \mathbf{q}_{k}$.
        \item Find $\mathbf{y}^{\left(k\right)}$ which minimize ${\left|\left|\mathbf{r}^{\left(k\right)}\right|\right|}_{2}$.
        \item Compute the result $\mathbf{x}^{\left(k+1\right)} = \mathbf{x}^{\left(0\right)} + Q_{k}\mathbf{y}^{\left(k\right)}$.
    \end{enumerate}
\end{enumerate}
About the \textbf{convergence}:
\begin{itemize}
    \item If $A_{S} = \dfrac{\left(A + A^{T}\right)}{2}$ is SPD, then:
    \begin{equation}
        {\left|\left|\mathbf{r}^{\left(k\right)}\right|\right|}_{2} \le \left[1 - \dfrac{
            \lambda^{2}_{\min}\left(A_{S}\right)
        }{
            \lambda_{\max}\left(A^{T}A\right)
        }\right]^{\frac{k}{2}}
        {\left|\left|\mathbf{r}^{\left(0\right)}\right|\right|}_{2}
    \end{equation}

    \item If $A$ is SPD, then:
    \begin{equation}
        {\left|\left|\mathbf{r}^{\left(k\right)}\right|\right|}_{2} \le \left[\dfrac{
            \left[K_{2}\left(A\right)\right]^{2} - 1
        }{
            \left[K_{2}\left(A\right)\right]^{2}
        }\right]^{\frac{k}{2}}
        {\left|\left|\mathbf{r}^{\left(0\right)}\right|\right|}_{2}
    \end{equation}
\end{itemize}

\newpage

\begin{flushleft}
    \textcolor{Red2}{\faIcon{dollar-sign} \textbf{How much does it cost?}}
\end{flushleft}
The cost of each iteration depends by type of matrix:
\begin{itemize}
    \item \textbf{Dense matrix}: the cost of each iteration is about $n^{2}$ \textbf{operations}.
    \item \textbf{Sparse matrix}: the cost of each iteration is only about $n$ \textbf{operations}.
\end{itemize}
In addition to the matrix-vector product, $k \cdot n$ \textbf{operations} must be computed at the $k$-th iteration. Furthermore, the $k$-th iterate minimize the residual in the Krylov subspace $\mathcal{K}_{k}\left(A, \mathbf{r}^{\left(0\right)}\right)$. In exact arithmetic, since every subspace is contained in the next subspace, the residual does not increase. Therefore, after $n = \mathrm{size}\left(A\right)$ iterations, the Krylov space $\mathcal{K}_{n}\left(A, \mathbf{r}^{\left(0\right)}\right)$ is the whole of $\mathbb{R}^{n}$, hence the GMRES method has \textbf{finite termination property}. This, unfortunately, does not happen in practice.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{network-wired} \textbf{Can it be parallelized?}}
\end{flushleft}
GMRES \textbf{can be parallelized} on multi-core and many-core architectures, such as CPUs and GPUs.