\subsubsection{Jacobi method}

Let the problem of solve $Ax = b$, where $A$ is a square matrix, $x$ is the vector of unknowns, and $b$ is the result vector.

\highspace
We start from the $i$-th line of the linear system:
\begin{equation*}
    \displaystyle\sum_{j = 1}^{n} a_{ij}x_{j} = b_{i} \: \rightarrow \: a_{i1}x_{1} + a_{i2}x_{2} + \cdots + a_{in}x_{n} = b_{i}
\end{equation*}
Formally the solution $x_{i}$ for each $i$ si given by:
\begin{equation}
    x_{i} = \dfrac{b_{i}-\displaystyle\sum_{j \ne i} a_{ij}x_{j}}{a_{ii}}
\end{equation}
Obviously the previous identity cannot be used in practice because we do not know $x_{j}$, for $j \ne i$. And here is the \textbf{magic idea} of Jacobi: we could think of introducing an iterative method (Jacobi) that \textbf{updates} $x_{i}^{\left(k+1\right)}$ \textbf{step} $k+1$ \textbf{using the other} $x_{j}^{\left(k\right)}$ \textbf{obtained in the previous step} $k$.
\begin{equation}\label{eq: jacobi x calcolus}
    x_{i} = \dfrac{b_{i}-\displaystyle\sum_{j \ne i} a_{ij}x_{j}}{a_{ii}} \: \xRightarrow{\text{as }x_{j}\text{ is not well known}} \: x_{i}^{\left(k+1\right)} = \dfrac{b_{i}-\displaystyle\sum_{j \ne i} a_{ij}x_{j}^{\left(k\right)}}{a_{ii}}
\end{equation}
Where $\forall i = 1, \dots, n$.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{tools} \textbf{Algorithm}}
\end{flushleft}
\begin{enumerate}
    \item \textbf{Start with an initial guess} $x^{\left(0\right)}$, also zero.
    \item \textbf{Update each component} $x_{i}^{\left(k+1\right)}$ using the equation \ref{eq: jacobi x calcolus}.
    \item \textbf{Repeat until the changes are less than a specified tolerance} or we haven't found the exact solution (in practice very difficult, almost impossible).
\end{enumerate}

\highspace
\begin{flushleft}
    \textcolor{Red2}{\faIcon{dollar-sign} \textbf{How much does it cost?}}
    \label{general-ref: cost jacobi method}
\end{flushleft}
It depends on the matrix used:
\begin{itemize}
    \item \textbf{Dense matrix} (bad choice). Each iteration costs $\approx n^{2}$ operations, so the Jacobi method is competitive if the number of iteration is less than $n$.
    \item \textbf{Sparse matrix} (good choice). Each iteration costs only $\approx n$ operations.
\end{itemize}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{network-wired} \textbf{Can it be parallelized?}}
\end{flushleft}
The parallelization of the Jacobi method is actually \textbf{one of its main advantages} on modern computers. Each update of $x_{i}$ depends only on the previous values of the other $x_{j}$, not on the current iteration values. This independence makes it easy to distribute the work across multiple processors.
