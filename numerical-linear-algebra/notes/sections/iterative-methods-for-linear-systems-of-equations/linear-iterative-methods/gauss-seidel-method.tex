\subsubsection{Gauss-Seidel method}

Given the Jacobi method, the Gauss Seidel method is similar, but with one clever difference: it uses the latest available values during iterations.
\begin{equation}\label{eq: gauss seidel x calcolus}
    x_{i}^{\left(k+1\right)} = \dfrac{b_{i} - \displaystyle\sum_{j < i} a_{ij}x_{j}^{\left(k+1\right)} - \displaystyle\sum_{j > i}a_{ij}x_{j}^{\left(k\right)}}{a_{ii}}
\end{equation}
At iteration $\left(k+1\right)$, let's consider the computation of $x_{i}^{\left(k+1\right)}$. We observe that for $j < i$ (with $i \ge 2$), $x_{j}^{\left(k+1\right)}$ is known (we have already calculated it). We can therefore think of using the quantities at step $\left(k+1\right)$ if $j<i$ and, as in the Jacobi method, those at the previous step $k$ if $j > i$.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{tools} \textbf{Algorithm}}
\end{flushleft}
\begin{enumerate}
    \item \textbf{Start with an initial guess} $\mathbf{x}^{\left(0\right)}$, also zero.
    \item \textbf{Iteration}. For each row $i$ from $1$ to $n$ calculate the value of the equation \ref{eq: gauss seidel x calcolus}.
    \item \textbf{Repeat until the changes are less than a specified tolerance}.
\end{enumerate}

\highspace
\begin{flushleft}
    \textcolor{Red2}{\faIcon{dollar-sign} \textbf{How much does it cost?}}
\end{flushleft}
The cost is comparable to the Jacobi method explained on page \pageref{general-ref: cost jacobi method}.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{network-wired} \textbf{Can it be parallelized?}}
\end{flushleft}
Unlike the Jacobi method, the Gauss-Seidel method relies on the most recent updates within the same iteration. This sequential dependency \textbf{makes it more difficult to parallelize, as each update depends on the previous ones}.

\highspace
While it's harder to parallelize due to its inherent sequential nature, we can still achieve some degree of parallelism with clever strategies such as red-black ordering. This makes the Gauss-Seidel method less straightforward to parallelize than Jacobi, but not impossible.
