\subsection{Metodi numerici per sistemi non lineari}

\subsubsection{Introduzione}

Molto spesso i problemi ingegneristici sono \emph{non lineari}. Per risolvere tali problemi in modo ottimale, si adotta l'approssimazione numerica, la quale porta a dover risolvere un \textbf{sistema di equazioni non lineari}.

\highspace
In generale, si ha il seguente problema:
\begin{equation*}
	\mathbf{f}\left(\mathbf{x}\right) = \mathbf{0} \longleftrightarrow \begin{cases}
		f_{1}\left(x_{1}, \dots, x_{j}, \dots, x_{n}\right) = 0 \\
		\dots \\
		f_{i}\left(x_{1}, \dots, x_{j}, \dots, x_{n}\right) = 0 \\
		\dots
		f_{n}\left(x_{1}, \dots, x_{j}, \dots, x_{n}\right) = 0
	\end{cases}
\end{equation*}
Dove:
\begin{itemize}
	\item $\mathbf{x} \in \mathbb{R}^{n}$ è il vettore delle incognite $x_{j}$
	
	\item $\mathbf{f}$ è una funzione del tipo $\mathbf{f}: \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}$
	
	\item $f_{i}$ sono funzioni che esprimono relazioni non lineari fra le incognite
\end{itemize}
Questo caso è un \textbf{problema poiché presenta due principali difficoltà} dal punto di vista numerico:
\begin{enumerate}
	\item Si è di fronte ad un \textbf{sistema}, per cui non si hanno equazioni singole.
	
	\item Inoltre, il sistema è \textbf{non lineare}, e questo significa che deve essere linearizzato per poterlo risolvere.
\end{enumerate}

\newpage

\subsubsection{Metodo di Newton}

Il metodo di newton per sistemi lineari era stato introdotto nel paragrafo \ref{subsection: il metodo di newton per sistemi lineari} (pagina \pageref{subsection: il metodo di newton per sistemi lineari}). Può essere riscritto in modo equivalente per sistemi non lineari nel seguente modo.

\highspace
Se la funzione $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$ con $n \ge 1$, è di classe $C^{2} \left(\mathbb{R}^{n}\right)$, e se è possibile calcolare le sue derivate prime e seconde, allora è possibile applicare il metodo di Newton all'equazione vettoriale $\mathbf{f}\left(\mathbf{x}\right) = \nabla f\left(\mathbf{x}\right) = \mathbf{0}$ per calcolare il punto di minimo $\mathbf{x}^{*}$.

\highspace
Dunque, il \definition{metodo di Newton per sistemi non lineari} si formula nel seguente modo. Dato $\mathbf{x}^{\left(0\right)} \in \mathbb{R}^{n}$, per $k = 0, 1, \dots$ e fino a convergenza, si deve:
\begin{equation}
	\begin{array}{ll}
		\text{risolvere} & \mathrm{H}\left(\mathbf{x}^{\left(k\right)}\right)\mathbf{\delta}\mathbf{x}^{\left(k\right)} = -\nabla \mathbf{f}\left(\mathbf{x}^{\left(k\right)}\right) \\ [1em]
		\text{ponendo} 	 & \mathbf{x}^{\left(k+1\right)} = \mathbf{x}^{\left(k\right)} + \mathbf{\delta}\mathbf{x}^{\left(k\right)}
	\end{array}
\end{equation}
È interessante notare che la matrice Hessiana utilizzata ne metodo di Newton è uguale alla matrice Jacobiana $J_{\mathbf{f}}\left(\mathbf{x}^{\left(k\right)}\right)$ valutata nel punto $\mathbf{x}^{\left(k\right)}$.

\highspace
Dato un punto $z \in \mathbb{R}^{n}$, si introduce la matrice Jacobiana relativa a $\mathbf{f}$:
\begin{equation}
	J\left(\mathbf{z}\right) = \nabla \mathbf{f}\left(\mathbf{z}\right)
\end{equation}
Di componenti:
\begin{equation}
	j_{il} = \dfrac{\partial f_{i}\left(\mathbf{z}\right)}{\partial x_{l}} \hspace{2em} i,l = 1, \dots, n
\end{equation}
Per ogni $\mathbf{x} \in \mathbb{R}^{n}$ si ha quindi $J\left(\mathbf{z}\right) \in \mathbb{R}^{n \times n}$. Avendo definito la matrice Jacobiana non singolare (determinante diverso da zero), si può riscrivere il metodo di Newton in modo alternativo nel seguente modo:
\begin{equation}
	\begin{array}{ll}
		\text{risolvere} & \mathrm{J}\left(\mathbf{x}^{\left(k\right)}\right)\mathbf{\delta}\mathbf{x}^{\left(k\right)} = -\mathbf{f}\left(\mathbf{x}^{\left(k\right)}\right) \\ [1em]
		\text{ponendo} 	 & \mathbf{x}^{\left(k+1\right)} = \mathbf{x}^{\left(k\right)} + \mathbf{\delta}\mathbf{x}^{\left(k\right)}
	\end{array}
\end{equation}

\begin{flushleft}
	\textcolor{Green3}{\faIcon{list-ol} \textbf{Algoritmo}}
\end{flushleft}
\underline{Ad ogni iterazione $k$}, il primo passo del metodo di Newton consiste nella risoluzione di un sistema lineare di dimensione $n$:
\begin{enumerate}
	\item Risolvere il sistema lineare $n \times n$:
	\begin{equation*}
		\mathrm{J}\left(\mathbf{x}^{\left(k\right)}\right)\mathbf{\delta}\mathbf{x}^{\left(k\right)} = -\mathbf{f}\left(\mathbf{x}^{\left(k\right)}\right)
	\end{equation*}
	Infatti $\mathrm{J}\left(\mathbf{x}^{\left(k\right)}\right)$ è una matrice non singolare di coefficienti noti:
	\begin{equation*}
		\dfrac{\partial f_{i}\left(\mathbf{x}^{\left(k\right)}\right)}{\partial x_{l}}
	\end{equation*}
	E $-\mathbf{f}\left(\mathbf{x}^{\left(k\right)}\right)$ è il termine noto.
	
	\item Una volta risolto il sistema lineare e ottenuto $\delta\mathbf{x}^{\left(k\right)}$, si aggiorna la variabile $\mathbf{x}^{\left(k+1\right)}$ mediante il secondo passo del metodo:
	\begin{equation*}
		\mathbf{x}^{\left(k+1\right)} = \mathbf{x}^{\left(k\right)} + \delta\mathbf{x}^{\left(k\right)}
	\end{equation*}
\end{enumerate}
Come detto, questo procedimento avviene ad ogni iterazione $k$!

\highspace
Il metodo di Newton, può essere considerato un:
\begin{itemize}
	\item \textbf{Metodo locale} se:
	\begin{itemize}
		\item Esiste un $\delta > 0$
		
		\item È vera la condizione:
		\begin{equation*}
			\left|\left|\mathbf{\alpha} - \mathbf{x}^{\left(0\right)}\right|\right| < \delta
		\end{equation*}
	\end{itemize}
	Per cui:
	\begin{equation*}
		\lim\limits_{k \rightarrow \infty} \left|\left|\mathbf{\alpha} - \mathbf{x}^{\left(k\right)}\right|\right| = 0
	\end{equation*}
	
	\item \textbf{Metodo del secondo ordine} se:
	\begin{itemize}
		\item Newton converge
		
		\item La matrice Jacobiana $J$ è derivabile
	\end{itemize}
	Per cui:
	\begin{equation*}
		\dfrac{
			\left|\left|\mathbf{\alpha} - \mathbf{x}^{\left(k+1\right)}\right|\right|
		}{
			\left|\left|\mathbf{\alpha} - \mathbf{x}^{\left(k\right)}\right|\right|^{2}
		} \le C
	\end{equation*}
\end{itemize}
Si ricorda che $\mathbf{\alpha}$ sono le radici di $\mathbf{f}$.

\highspace
\begin{flushleft}
	\textcolor{Green3}{\faIcon{question-circle} \textbf{Criteri d'arresto}}
\end{flushleft}
Dato che il metodo di Newton è un metodo iterativo, è necessario introdurre opportuni criteri di arresto. Quindi:
\begin{itemize}
	\item Criterio sul \textbf{residuo}:
	\begin{equation}
		\left|\left|\mathbf{f}\left(\mathbf{x}^{\left(k\right)}\right)\right|\right| < \varepsilon
	\end{equation}
	
	\item Criterio sull'\textbf{incremento}:
	\begin{equation}
		\left|\left|\mathbf{x}^{\left(k+1\right)} - \mathbf{x}^{\left(k\right)}\right|\right| < \varepsilon
	\end{equation}
\end{itemize}
Scegliendo un'opportuna tolleranza $\varepsilon$.

\newpage

\begin{flushleft}
	\textcolor{Green3}{Costi computazionali e varianti ottimizzate}
\end{flushleft}
Il metodo di Newton per sistemi non lineari, richiede come \textbf{costo computazionale}:
\begin{equation}\label{eq: costo computazionale metodo di newton per sistemi non lineari}
	\texttt{CPU TIME} = \# \: \text{iterazioni} \times \left(C_{cos} + C_{sl}\right)
\end{equation}
Dove:
\begin{itemize}
	\item $C_{cos}$ è il \textbf{tempo} necessario per \textbf{costruire la matrice Jacobiana} $J\left(\mathbf{x}^{\left(k\right)}\right)$.
	
	\item $C_{sl}$ è il \textbf{tempo} di \textbf{risoluzione} del corrispondente \textbf{sistema lineare}.
\end{itemize}
Si possono fare alcune osservazioni riguardo questo calcolo:
\begin{itemize}
	\item La matrice Jacobiana $J\left(\mathbf{x}^{\left(k\right)}\right)$ deve essere ricostruita ad ogni iterazione.
	
	\item Generalmente, il numero di iterazioni ($\# \: \text{iterazioni}$) è molto basso poiché il metodo di Newton è di ordine 2.
\end{itemize}
In ogni caso, a causa di un tempo di processo alto nei casi di sistemi lineari con ordini maggiori, esistono due principali alternative:
\begin{enumerate}
	\item \definition{Aggiornamento Jacobiana ogni $p$ iterazioni}. Dato un numero intero $p \ge 2$, l'idea è quella di aggiornare la matrice Jacobiana $J\left(\mathbf{x}^{\left(k\right)}\right)$ solo ogni $p$ volte.
	
	Così facendo, il tempo di costruzione della matrice Jacobiana $C_{\text{cos}}$ viene ridotto, dato che si riduce a $p$ iterazioni.
	
	In questo metodo, si definisce $C_{\text{cos} - \text{Newton}}$ il tempo di costruzione della matrice Jacobiana che si avrebbe applicando il semplice metodo di Newton (e non tale variante!). E la variabile $C_{\text{cos}}$ nella formula \ref{eq: costo computazionale metodo di newton per sistemi non lineari} diventa:
	\begin{equation}
		C_{\text{cos}} = \dfrac{C_{\text{cos} - \text{Newton}}}{p}
	\end{equation}
	Ovviamente $p$ sono il numero di iterazioni.
	
	Infine, utilizzando la fattorizzazione LU per la risoluzione del sistema lineare, il costo della fattorizzazione della matrice Jacobiana $J\left(\mathbf{x}^{\left(k\right)}\right)$ è suddiviso su $p$ iterazioni. Di fatto, ad ogni iterazione mediamente si ha un costo di:
	\begin{equation*}
		\dfrac{2n^{3}}{3p}
	\end{equation*}
	Tuttavia, così facendo, il numero di iterazioni è nettamente maggiore a quello del secondo ordine. Un numero di iterazioni troppo elevato rischia di perdere la convergenza. Per questo motivo, si dovrebbe rispettare la seguente relazione:
	\begin{equation}
		\# \text{iterazioni} \times \dfrac{\left(C_{\text{cos}} + C_{\text{sl}}\right)}{p} < \# \text{iterazioni} \times \left(C_{\text{cos}} + C_{\text{sl}}\right)
	\end{equation}
	
	
	\item \definition{Inexact Newton}. L'idea è quella di sostituire ad ogni iterazione $k$ la matrice Jacobiana $J\left(\mathbf{x}^{k}\right)$ con una sua approssimazione $\tilde{J}^{k}$ che sia in generale facilmente costruibile e tale che il sistema lineare associato sia facilmente risolvibile.
	
	Tale tecnica è un \textbf{metodo esatto}, quindi raggiunta la convergenza la soluzione è $\mathbf{\alpha}$ (la parola \emph{inexact} si riferisce alla matrice Jacobiana!).
\end{enumerate}